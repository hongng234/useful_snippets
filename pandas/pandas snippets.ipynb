{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files, Select columns and Summarizing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Reading in a file from local computer or directly from a URL\n",
    "# Various file formats that can be read\n",
    "    \n",
    "Format Type     Data Description      Reader           Writer\n",
    "text                  CSV            read_csv          to_csv\n",
    "text                 JSON            read_json         to_json\n",
    "text                 HTML            read_html         to_html\n",
    "text             Local clipboard  read_clipboard     to_clipboard\n",
    "binary             MS Excel          read_excel        to_excel\n",
    "binary            HDF5 Format        read_hdf           to_hdf\n",
    "binary           Feather Format     read_feather      to_feather\n",
    "binary              Msgpack         read_msgpack      to_msgpack\n",
    "binary               Stata           read_stata        to_stata\n",
    "binary                SAS             read_sas \n",
    "binary        Python Pickle Format   read_pickle       to_pickle\n",
    "SQL                   SQL             read_sql          to_sql\n",
    "SQL             Google Big Query      read_gbq          to_gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file from local or from a URL\n",
    "df = pd.read_csv('local_path/file.csv')\n",
    "df = pd.read_csv('https://file_path/file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a tables, can specify separators\n",
    "df = pd.read_table('https://file_path/file', sep='|', index_col='column_x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the df data\n",
    "df                                        #print the first 30 and last 30 rows\n",
    "type(df)                                  #type dataframe\n",
    "df.head()                                 #print the 1st 5 rows\n",
    "df.head(10)                               #print the 1st 10 rows\n",
    "df.tail()                                 #print the last 5 rows\n",
    "df.tail(10)                               #print the last 10 rows\n",
    "df.index                                  #show the index column\n",
    "df.columns                                #show all columns names in an array\n",
    "df.dtypes                                 #show data types of each column\n",
    "df.shape                                  #show the shape of the dataframe(number of rows and columns)\n",
    "df.values                                 #show all the values of the dataframe(show as a numpy array for efficiencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a column\n",
    "df['column_x']                            #select specified column\n",
    "type(df['column_x'])                      #show the datatype of specified column (e.g Series)\n",
    "df.column_x                               #select the specified column using the dataframe attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize(describe) a dataframe\n",
    "df.describe()                             #describe all numeric columns\n",
    "df.describe(include=['object'])           #describe all object columns\n",
    "df.describe(include='all')                #describe all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize a Series\n",
    "df.column_x.describe()                    #describe a single column\n",
    "df.column_x.mean()                        #only calculate the mean of the specified column\n",
    "df['column_x'].mean()                     #alternative method to calculate the mean of the specified column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurences of each value\n",
    "df.column_x.value_counts()                #most useful for categorical variables, but can also be used with numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe by specified column, and print out values of another column\n",
    "df[df.column_x == 'string_value'].column_y\n",
    "df[df.column_x == 1].column_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display only the number of rows of the dataframe\n",
    "df.shape[0]\n",
    "# Display only the number of column of the dataframe\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 3 most frequent occurances of column in dataframe\n",
    "df.column_x.value_counts()[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering and Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean filtering: only show df with column_x < 20\n",
    "filter_bool = df.columns_x < 20                       #create a series of booleans with condition <20 of a specified column...\n",
    "df[filter_bool]                                       #..and use that series to filter rows\n",
    "df[filter_bool].describe()                            #describe a dataframe filtered by filter_bool\n",
    "df[df.column_x < 20]                                  #or, combine into a single step\n",
    "df[df.column_x < 20].column_y                         #select one column from the filtered results of column_x\n",
    "df[df['column_x'] < 20].column_y                      #alternative method\n",
    "df[df.column_x < 20].column_y.value_counts()          #value_counts of result series, can also use mean() instead of value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean filtering with multiple conditions\n",
    "df[(df.column_x < 20) & (df.column_y == 'string')]    #ampersand for AND condition\n",
    "df[(df.column_x < 20) | (df.column_y > 60)]           #pipe for OR condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting\n",
    "df.column_x.order()                                   #sort a column\n",
    "df.sort_values('column_x')                            #sort a dataframe by a single column\n",
    "df.sort_values('column_x', ascending=False)           #use descending order instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe by multiple columns\n",
    "df = df.sort(['col1','col2','col3'], ascending=[1,1,0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also filter dataframe using pandas.Series.isin\n",
    "df[df.column_x.isin(['string_1','string_2'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming, Adding and Removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename one or more columns\n",
    "df.rename(columns={'original_column_1':'column_x','original_column_2':'column_y'}, inplace=True)   #Saves changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all column names (in place)\n",
    "new_cols = ['column_x','column_y','column_z']\n",
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all column names when reading the file\n",
    "df = pd.read_csv('df.csv', header=0, names=new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column as a function of existing columns\n",
    "df['new_column_1'] = df.column_x + df.column_y\n",
    "df['new_column_2'] = df.column_x * 1000           #can create new columns without for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing columns\n",
    "df.drop('column_x', axis=1)                              # axis=0 for rows, axis=1 for columns - does not drop in place\n",
    "df.drop(['column_x','column_y'], axis=1, inplace=True)   # drop multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower_case and upper_case all datafram column names\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df.columns = map(str.upper, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even more fancy dataframe column re-nameing\n",
    "# lower_case all dataframe column names \n",
    "df.rename(columns=lambda x: x.split('.')[-1], inplace=True)           # ????"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values are usually excluded by default\n",
    "df.column_x.value_counts()                               #exclude missing values\n",
    "df.column_x.value_counts(dropna=False)                   #include missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values in a Series\n",
    "df.column_x.isnull()                                     #True if missing\n",
    "df.column_x.notnull()                                    #True if not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a boolean Series to filter dataframe rows\n",
    "df[df.column_x.isnull()]                                 #only show rows where column_x is missing\n",
    "df[df.column_x.notnull()]                                #only show rows where column_x not missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding axis\n",
    "df.sum()                                                 #sums 'down' the 0 axis(rows)\n",
    "df.sum(axis=0)                                           #alternative(since axis=0 is default)\n",
    "df.sum(axis=1)                                           #sums 'across' the 1 axis(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding booleans\n",
    "pd.Series([True, False, True])                           #create a boolean Series\n",
    "pd.Series([True, False, True]).sum()                     #converts False to 0 and True to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find missing values in dataframe\n",
    "df.isnull()                                              #dataframe of booleans\n",
    "df.isnull().sum()                                        #count the missing values in each column\n",
    "df.isnull().sum().sum()                                  #count the total missing values of all dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing values\n",
    "df.dropna(inplace=True)                                  #drop a row if ANY values are missing, default to rows, but can be applied to columns with axis=1\n",
    "df.dropna(how='all', inplace=True)                       #drop a row only if ALL values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "df.column_x.fillna(value='NaN', inplace=True)            #fill the missing values of column_x with 'NaN'\n",
    "df.column_x.fillna(value=np.nan, inplace=True)           #alternative use numpy library\n",
    "#value does not have to equal a string - can be set as some calculated value like df.column_x.mode(), or just a number like 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off the missing value filter\n",
    "df = pd.read_csv('df.csv', header=0, names=new_cols, na_filter=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split, Apply, Combine\n",
    "Diagram: http://i.imgur.com/yjNkiwL.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each value in column_x, calculate the mean of column_y\n",
    "df.groupby('column_x').column_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each value in column_x, count the number of occurences\n",
    "df.column_x.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each value in column_x, describe column_y\n",
    "df.groupby('column_x').column_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar, but outputs a dataframe can be customized\n",
    "df.groupby('column_x').column_y.agg(['count','mean','min','max'])\n",
    "df.groupby('column_x').column_y.agg(['count','mean','min','max']).sort_values('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If dont specify a column to which the aggregation function should be applied, it will applied to all numeric columns\n",
    "df.groupby('column_x').mean()\n",
    "df.groupby('column_x').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also groupby a list of columns, i.e, for each combination of column_x and column_y, calculate the mean of column_z\n",
    "df.groupby(['column_x', 'column_y']).column_z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to take groupby results out of hierarchical index format(e.g, present as table), use .unstack() method\n",
    "df.groupby('column_x').column_y.value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversely, if we want to transform a table into a hierarchical index, use the .stack() method\n",
    "df.stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting multiple columns and Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select multiple columns\n",
    "my_cols = ['column_x','column_y']                  #create a list of column names\n",
    "df[my_cols]                                        #..and use that column names list to select columns\n",
    "df[['column_x','column_y']]                        #or, combine into a single step = double brackets due to indexing a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use loc to select columns by name\n",
    "df.loc[:, 'column_x']                              #colon means 'all rows', then select one column (column_x in this case)\n",
    "df.loc[:, ['column_x','column_y']]                 #select two columns\n",
    "df.loc[:, 'column_x':'column_y']                   #select a range of columns(i.e., select all columns including 1st column through last specified column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loc can also filter rows by 'name' (the index)\n",
    "df.loc[0, :]                                       #row 0, all columns\n",
    "df.loc[0:2, :]                                     #row 0-1-2, all columns\n",
    "df.loc[0:2, 'column_x':'column_y']                 #row 0-1-2, all columns in range of column_x to column_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use iloc to filter rows and select columns by integer position\n",
    "df.iloc[:, [0, 3]]                                 #all rows, columns in position 0 and 3\n",
    "df.iloc[:, 0:4]                                    #all rows, columns in position 0-1-2-3\n",
    "df.iloc[0:3, :]                                    #rows in position 0-1-2, all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out and dropping rows based on condition(e.g, where column_x values are null)\n",
    "drop_rows = df[df['column_x'].isnull()]\n",
    "new_df = df[~df.isin(drop_rows)].dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging and Concatenating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating two dfs together, just put them together, does not pair them in any meaningful way\n",
    "# - axis=1 concat df2 to right side of df1, axix=0 concat df2 to bottom of df1\n",
    "new_df = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging dfs based on paired columns, columns do not need to have same name, but shold match values\n",
    "# - left_on column come from df1, right_on column come from df2\n",
    "new_df = pd.merge(df1, df2, left_on='column_x', right_on='column_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also merge slices of dfs together, though slices need to include columns used for merging\n",
    "new_df = pd.merge(df1[['column_x1','column_x2']], df2, left_on='column_x2', right_on='column_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two dataframes based on shared index values (left is df1, right is df2)\n",
    "new_df = pd.merge(df1, df2, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other frequently used features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map existing values to a different set of values\n",
    "df['column_x'] = df.column_y.map({'F':0,'M':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode strings as integer values (automaticaly starts at 0)\n",
    "df['column_x_num'] = df.column_x.factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine unique values in a column\n",
    "df.column_x.nunique()                                    #count the number of unique values of column_x\n",
    "df.column_x.unique()                                     #return all the unique values of column_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all instances of a value in a column (must match entire value)\n",
    "df.column_y.replace('old_string', 'new_string', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alter values in one column based on values in another column(change occur in place)\n",
    "#can use either .loc or .ix methods\n",
    "df.loc[df['column_x'] == 5, 'column_y'] = 1\n",
    "df.ix[df.column_x == 'string_value', 'column_y'] = 'new_string_value'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose dataframe (i.e rows become columns, columns become rows)\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# String methods are accessed via 'str'\n",
    "df.column_x.str.upper()                                 #converts to uppercase\n",
    "df.column_x.str.lower()                                 #converts to lowercase\n",
    "df.column_x.str.contains('value', na='False')           #checks for a substring, returns boolean series\n",
    "\n",
    "df.column_x.str[0:5]                                    #slice values in column_x\n",
    "df.column_x.str.len()                                   #get length of data in column_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert a string to the datetime_column format\n",
    "df['time_column'] = pd.to_datetime_column(df.time_column)\n",
    "df.time_column.dt.hour                                  #datetime_column format exposes convenient attributes\n",
    "(df.time_column.max() - df.time_column.min()).days      #also allows you to do datetime_column 'math'\n",
    "df[df.time_column > pd.datetime_column(2019,1,1)]       #boolean filtering with datetime_column format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting and then removing an index, reseting index can help remove hierarchical indexes while preserving the table in its basic structure\n",
    "df.set_index('time_column', inplace=True)               #set the time_column as an index of the dataframe\n",
    "df.reset_index(inplace=True)                            #reset the order of the index (i.e. usually used after drop one or many rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort a column by its index\n",
    "df.column_x.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of a column\n",
    "df['column_x'] = df.column_x.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type of a column when reading in a file\n",
    "pd.read_csv('df.csv', dtype={'column_x':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummpy variables for 'column_x' and exclude the 1st dummy column\n",
    "column_x_dummies = pd.get_dummies(df.column_x).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two dataframes (axis=0 for rows, axis=1 for columns)\n",
    "df = pd.concat([df, column_x_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert series datatype to numeric datatype (will error if column has non_numeric values)\n",
    "pd.to_numeric(df['column_x'])\n",
    "\n",
    "# Convert series datatype to numeric datatype, changing non-numeric values to NaNs\n",
    "pd.to_numeric(df['column_x'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab dataframe rows where column has certain values in the given list\n",
    "value_list = ['value_1','value_2','value_3']\n",
    "df = df[df.column.isin(value_list)]\n",
    "\n",
    "# Grab dataframe rows where column doesn't have certain values in the given list\n",
    "value_list = ['value_1','value_2','value_3']\n",
    "df = df[~df.column.isin(value_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete column from dataframe\n",
    "del df['column_x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename several dataframe columns\n",
    "df = df.rename(columns={\n",
    "    'col1 old name':'col1 new name',\n",
    "    'col2 old name':'col2 new name',\n",
    "    'col3 old name':'col3 new name'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Less Frequently Used Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from a dictionary\n",
    "pd.DataFrame({'column_x': ['value_x1','value_x2','value_x3'], 'column_y': ['value_y1','value_y2','value_y3']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe from a list of lists\n",
    "pd.DataFram([['value_x1','value_y1'],['value_x2','value_y2'],['value_x3','value_y3']], columns=['column_x','column_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting duplicate rows\n",
    "df.duplicated()                                             #True if a row is identical to previous row\n",
    "df.duplicated().sum()                                       #count of duplicates of each columns\n",
    "df.duplicated().sum().sum()                                 #count of duplicates of all dataframe(final sum from sum of columns)\n",
    "df[df.duplicated()]                                         #only show duplicates\n",
    "df.drop_duplicates()                                        #drop duplicate rows\n",
    "df.column_x.duplicated()                                    #check a single column for duplicates\n",
    "df.duplicated(['column_x','column_y','column_z']).sum()     #specify columns for finding duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up missing values in multiple dataframe columns\n",
    "df = df.fillna({\n",
    "    'col1':'missing',\n",
    "    'col2':'99.999',\n",
    "    'col3':'999',\n",
    "    'col4':'missing',\n",
    "    'col5':'missing',\n",
    "    'col6':'99'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate two dataframe columns into a new, single column (useful when dealing with composite keys, for example)\n",
    "df['new_col'] = df['col1'].map(str) + df['col2'].map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing calculations with dataframe columns that have missing values\n",
    "# in example below, swap in 0 for df['col1'] cells that contain null values\n",
    "df['new_col'] = np.where(pd.isnull(df['col1']), 0, df['col1']) + df['col2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a cross-tabulation of two Series\n",
    "pd.crosstab(df.column_x, df.column_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative syntax for boolean filtering (noted as 'experimental' in the documentation)\n",
    "df.query('çolumn_x < 20')                                  # df[df.column_x < 20]\n",
    "df.query(\" column_x < 20 and column_y == 'string' \")       # df[(df.column_x < 20) & (df.column_y == 'string')]\n",
    "df.query('column_x < 20 or column_y > 60')                 # df[(df.column_x < 20) | (df.column_y > 60)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through rows in dataframe\n",
    "for index, row in df.iterrows():\n",
    "    print(index, row['column_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much faster way to loop through dataframe rows if you can work with tuples\n",
    "for row in df.itertuples():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of non-numeric values throughout a dataframe\n",
    "for col in df.columns.values:\n",
    "    df[col] = df[col].replace('[0-9]+.-','', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change all NaNs to None (useful before loading to a db)\n",
    "df = df.where((pd.notnull(df)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split delimited values in a dataframe column into two new columns\n",
    "df['new_col1'], df['new_col2'] = zip(*df['original_col'].apply(lambda x: x.split(':', 1)))    #split data on the left and right of delimiter ':' into 2 new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse hierarchical column indexes\n",
    "df.columns = df.columns.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the memory usage of dataframe\n",
    "df.info()                                    #total usage\n",
    "df.memory_usage()                            #usage by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change a series to the 'category' data type (reduces memory usage and increase performance)\n",
    "df['column_x'] = df.column_x.astype('çategory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily define a new column as a function of existing columns\n",
    "df.assign(new_column = df.column_x + df.spirit + df.column_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit which rows are read when reading in a file\n",
    "pd.read_csv('df.csv', nrows=10)              #only read 1st 10 rows\n",
    "pd.read_csv('df.csv', skiprows=[1,2])        #skip the first two rows of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly sample a dataframe\n",
    "train = df.sample(frac=0.75, random_column_y=1)  #will contain 75% of the rows\n",
    "test = df[~df.index.isin(train.index)]           #will contain the orther 25% of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the maximum number of rows and columns printed('None' mean unlimited)\n",
    "pd.set_option('max_rows', None)                  #default is 60 rows\n",
    "pd.set_option('max_columns', None)               #default is 20 columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset options to defaults\n",
    "pd.reset_option('max_rows')\n",
    "pd.reset_option('max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the options temporarily (settings are restored when you exit the 'with' block)\n",
    "with pd.option_context('max_rows', None, 'max_columns', None):\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
